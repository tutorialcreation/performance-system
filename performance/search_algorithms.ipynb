{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SynchronousOnlyOperation",
     "evalue": "You cannot call this from an async context - use a thread or sync_to_async.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSynchronousOnlyOperation\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc1caaa50d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#clean the data InputData.objects.filter(n.first().number_of_levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/performance-system-aN5o6ifg/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/performance-system-aN5o6ifg/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/performance-system-aN5o6ifg/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1582\u001b[0m             \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m             \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/performance-system-aN5o6ifg/lib/python3.6/site-packages/django/utils/asyncio.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mevent_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mSynchronousOnlyOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Pass onwards.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSynchronousOnlyOperation\u001b[0m: You cannot call this from an async context - use a thread or sync_to_async."
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"setup.settings\")\n",
    "import django\n",
    "django.setup()\n",
    "\n",
    "from pams_system.models.levels import InputData,Level, KPIWeightings\n",
    "from django.db import connection\n",
    "import pandas as pd\n",
    "\n",
    "query = str(InputData.objects.all().query)\n",
    "df = pd.read_sql_query(query, connection)\n",
    "#clean the data InputData.objects.filter(n.first().number_of_levels\n",
    "df[['value_date']] = df[['value_date']].astype(object).where(df[['value_date']].notnull(), None)\n",
    "\n",
    "def get_value_dates(matching_string):\n",
    "    required_data = df[df['name'].str.contains(matching_string)]\n",
    "    preprocessed_value_dates = required_data['value_date']\n",
    "    cleaned_value_dates = preprocessed_value_dates.reset_index()\n",
    "    cleaned_value_dates.columns = ['indices','value_dates']\n",
    "    return cleaned_value_dates\n",
    "\n",
    "def get_weights(matching_string):\n",
    "    query_2 = KPIWeightings.objects.filter(content_id__name__icontains=matching_string).values(\"final_weight\")\n",
    "    df_2 = pd.DataFrame(query_2)\n",
    "#     df_2[['final_weight']] = df_2[['final_weight']].astype(object).where(df_2[['final_weight']].notnull(), None)\n",
    "    cleaned_weights =  df_2.dropna()\n",
    "    return cleaned_weights\n",
    "    \n",
    "def return_full_row(matching_string):\n",
    "    required_data = df[df['name'].str.contains(matching_string)]\n",
    "    preprocessed_data = required_data[['value_date','name']]\n",
    "    cleaned_data = preprocessed_data.reset_index()\n",
    "    cleaned_data.columns = ['indices','value_date','name']\n",
    "    return cleaned_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_string='Software'\n",
    "query_2 = KPIWeightings.objects.filter(content_id__name__icontains=matching_string).values(\"final_weight\")\n",
    "df_2 = pd.DataFrame(query_2)\n",
    "df_2[['final_weight']] = df_2[['final_weight']].astype(object).where(df_2[['final_weight']].notnull(), None)\n",
    "\n",
    "get_weights('Act')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_activities = 1/3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software_team_a = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = software_team_a * overall_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4*100)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"performance_analysis.xlsx\",sheet_name=\"analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_strategic_objective = df['strategic_objectives'] * df['Value_1']\n",
    "weighted_overall_activity = df['overall_activities'] * df['Value_2']\n",
    "weighted_departments = df['departments'] * df['Value_3']\n",
    "weighted_departmental_activity = df['departmental_activities'] * df['Value_4']\n",
    "weighted_kpis = df['kpis'] * df['Value_5']\n",
    "weighted_group_ind = df['group/individual'] * df['Value_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_group_ind.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['strategic_objectives'] * df['Value_1']\n",
    "df['overall_product'] = df['overall_activities'] * df['Value_2']\n",
    "df['department_product'] = df['departments'] * df['Value_3']\n",
    "df['dept_activities_product'] = df['departmental_activities'] * df['Value_4']\n",
    "df['kpi_product'] =df['kpis'] * df['Value_5']\n",
    "df['group_indiv_product'] = df['group/individual'] * df['Value_6']\n",
    "\n",
    "overall_activities_names = pd.Series([]) \n",
    "for i in range(len(data)): \n",
    "    if df[\"Value_2\"][i] == 78: \n",
    "        overall_activities_names[i]=\"Roll_Out/Implementation\"\n",
    "  \n",
    "    elif df[\"Value_2\"][i] == 70: \n",
    "        overall_activities_names[i]=\"Communication Materials\" \n",
    "  \n",
    "    elif df[\"Value_2\"][i] == 68: \n",
    "        overall_activities_names[i]=\"System Definition\"\n",
    "  \n",
    "    else: \n",
    "        overall_activities_names[i]= df[\"Value_2\"][i] \n",
    "# del df[\"overall_activities_names\"]\n",
    "# df.insert(3, \"overall_activities_names\", overall_activities_names)\n",
    "\n",
    "department_names = pd.Series([]) \n",
    "for i in range(len(data)): \n",
    "    if df[\"Value_3\"][i] == 67: \n",
    "        department_names[i]=\"Software Team A\"\n",
    "  \n",
    "    elif df[\"Value_3\"][i] == 72: \n",
    "        department_names[i]=\"Software Team B\" \n",
    "  \n",
    "    elif df[\"Value_3\"][i] == 75: \n",
    "        department_names[i]=\"Software Team C\"\n",
    "  \n",
    "    else: \n",
    "        department_names[i]= df[\"Value_3\"][i] \n",
    "# del df[\"department_names\"]\n",
    "# df.insert(6, \"department_names\", department_names)\n",
    "departmental_activities_names = pd.Series([]) \n",
    "departmental_activities_names = [\"Prepare code interpretations\",\"Prepare & test run system\",\n",
    "\"Conduct pilot installation\", \"Monitor & scrutinize pilot for system errors\", \n",
    "\"troubleshooting and bug fixes.\",\"To develop professional & presentable graphic user interface. Test user experience on the system.\",\"To create code documentations\",\n",
    "\"To create user manuals for training the staff that is the end user.\",\n",
    "\"To create a library of reusable code\",\"Prepare descriptions of all system functionalities and capture it in a master document.\", \n",
    "\"Prepare a User Manual for the system. Prepare user training presentations.\",\n",
    "\"Prepare FAQs on common questions and regular changes made on the system.\",\n",
    "\"Conduct system installations\",\"Undertake system maintenance\", \"Troubleshoot & provide user support\"]\n",
    "# del df[\"departmental_activities_names\"]\n",
    "# df.insert(9, \"departmental_activities_names\", departmental_activities_names)\n",
    "kpi_names = pd.Series([]) \n",
    "kpi_names = [\"Introductory System Write-up\",\"System Documentation\",\n",
    "\"User Manual/ FAQs\", \"Full implement the pilot\", \n",
    "\"Client feedback\",\"Processed graphic user interface\",\"Test Procedures\",\n",
    "\"System Documentation\",\n",
    "\"User Manuals\",\"FAQs\", \n",
    "\"Successful 1st-time installations completed\",\n",
    "\"Ongoing Improvement of System\",\n",
    "\"Ongoing user support\",\"UI feedback\", \"Quality Code\"]\n",
    "# del df[\"kpi_names\"]\n",
    "# df.insert(12, \"kpi_names\", kpi_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"strategic_objectives\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategic_objectives_sum = df[\"strategic_objectives\"].sum()\n",
    "def scale_down(x):\n",
    "    return x/strategic_objectives_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['strategic_objectives_weights'] = df['strategic_objectives'].apply(scale_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Unnamed: 0', 'strategic_objectives',  'strategic_objectives_weights','Value_1', 'overall_activities',\n",
    "       'overall_activities_names', 'Value_2', 'departments', 'Value_3',\n",
    "       'department_names', 'departmental_activities', 'Value_4',\n",
    "       'departmental_activities_names', 'kpis', 'Value_5', 'kpi_names',\n",
    "       'group/individual', 'Value_6', 'value_dates ', 'overall_product',\n",
    "       'department_product', 'dept_activities_product', 'kpi_product',\n",
    "       'group_indiv_product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['strategic_objectives_weights'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_down(df,column,group_column):\n",
    "    weight_column = \"_\".join([column,\"weights\"])\n",
    "    df[weight_column] = df.assign(**{weight_column:df[column]\\\n",
    "                                    /df.groupby(group_column)[column].transform('sum')})[weight_column]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_down(df,'kpis','department_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "def str_time_prop(start, end, format, prop):\n",
    "    stime = time.mktime(time.strptime(start, format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "    return time.strftime(format, time.localtime(ptime))\n",
    "def random_date(*args):\n",
    "    dates = []\n",
    "    for i in range(12):\n",
    "        dates.append(str_time_prop(\"12/12/2019\", \"10/11/2020\", '%m/%d/%Y', random.random()))\n",
    "    dates.sort(key=lambda x: time.mktime(time.strptime(x,\"%m/%d/%Y\")))\n",
    "    return dates\n",
    "# random_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "sdate = date(2014, 12, 21)   # start date\n",
    "edate = date(2008, 9, 15)   # end date\n",
    "\n",
    "delta = edate - sdate       # as timedelta\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = sdate + timedelta(days=i)\n",
    "    print(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list(np.random.uniform(0.5,0.92,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['Unnamed: 0', 'strategic_objectives', 'strategic_objectives_weights',\n",
    "#        'Value_1', 'overall_activities_names', 'overall_activities',\n",
    "#        'overall_activities_weights', 'Value_2', 'Value_3', 'department_names',\n",
    "#        'departments', 'departments_weights',\n",
    "#        'Value_4', 'departmental_activities_names','departmental_activities', 'departmental_activities_weights',\n",
    "#          'Value_5', 'kpi_names',\n",
    "#        'kpis', 'kpis_weights', 'group/individual', 'Value_6', 'value_dates ',\n",
    "#        'overall_product', 'department_product', 'dept_activities_product',\n",
    "#        'kpi_product', 'group_indiv_product' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_dates '] = df['value_dates '].apply(random_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_values(*args):\n",
    "    values = list(np.random.uniform(50,94,12))\n",
    "    return [round(val,2) for val in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_dates '] = df['value_dates '].apply(random_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value_6'] = df['Value_1'].apply(get_random_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.values\n",
    "data  = {}\n",
    "for column in columns:\n",
    "    if column.startswith('Value_') and not column.endswith('value_date'):\n",
    "#         print(df[column])\n",
    "        value_date_column = '_'.join([column,'value_date'])\n",
    "        df[value_date_column] = ''\n",
    "        df[value_date_column] = df[value_date_column].apply(random_date)\n",
    "        results = []\n",
    "        for value,date in zip(df[column].to_list(),df[value_date_column].to_list()):\n",
    "            results.append(dict(zip(value,date)))\n",
    "        data.update({column:results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_value_to_value_date(df):\n",
    "    columns = df.columns.values\n",
    "\n",
    "    data = {}\n",
    "    for column in columns:\n",
    "        if column.startswith('Value_') and not column.endswith(\"value_date\"):\n",
    "            each_value = []\n",
    "            value_date_colum = '_'.join([column, 'value_date'])\n",
    "            value_items = df[column].to_list()\n",
    "            value_date_items = df[value_date_colum].to_list()\n",
    "            for value, date in zip(value_items, value_date_items):\n",
    "                each_value.append(dict(zip(value, date)))\n",
    "            name = '_'.join([value_date_colum, 'mapper'])\n",
    "            data.update({name:each_value})\n",
    "            \n",
    "    df = pd.concat([df, pd.DataFrame(data)], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_latest_value_value_date(df, mapper_name):\n",
    "    data = []\n",
    "    for item in df[mapper_name]:\n",
    "        value = [*item][-1]\n",
    "        value_date = item[value]\n",
    "        data.append(value)\n",
    "    return data\n",
    "\n",
    "def get_product(df, value_date_mapper, weights, product_name):\n",
    "    latest_values = get_latest_value_value_date(df ,value_date_mapper)\n",
    "    weights_list = df[weights].to_list()\n",
    "    product = [a*b for a,b in zip(weights_list,latest_values)]\n",
    "    return pd.concat([df, pd.DataFrame(product, columns=[product_name])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_product(df,'Value_2_value_date_mapper','overall_activities_weights','overall_activity_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"performance_analysis_1.xlsx\",sheet_name=\"analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_value = get_latest_value_value_date(df,'Value_1_value_date_mapper')\n",
    "weights_list = df['strategic_objectives_weights'].to_list()\n",
    "product = [a*b for a,b in zip(latest_value,weights_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_ = df.iloc[2:3]['Value_1_value_date'].item()\n",
    "dates_.sort(key=lambda x: time.mktime(time.strptime(x,\"%m/%d/%Y\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value_2_value_date'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"performance_analysis_1.xlsx\",sheet_name=\"analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Unnamed: 0', 'strategic_objectives', 'strategic_objectives_weights',\n",
    "       'Value_1', 'overall_activities_names', 'overall_activities',\n",
    "       'overall_activities_weights', 'Value_2', 'Value_3', 'department_names',\n",
    "       'departments', 'departments_weights', 'Value_4',\n",
    "       'departmental_activities_names', 'departmental_activities',\n",
    "       'departmental_activities_weights', 'Value_5', 'kpi_names', 'kpis',\n",
    "       'kpis_weights', 'group/individual', 'Value_6', 'value_dates ',\n",
    "       'overall_product', 'department_product', 'dept_activities_product',\n",
    "       'kpi_product', 'group_indiv_product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(df) +1):\n",
    "    item = df.iloc[i-1:i]\n",
    "    overall_product = next(iter(item['overall_product']))\n",
    "    dept_activities_product = next(iter(item['dept_activities_product']))\n",
    "    kpi_product = next(iter(item['kpi_product']))\n",
    "    department_product = next(iter(item['department_product']))\n",
    "    \n",
    "    total = overall_product + dept_activities_product + kpi_product + department_product\n",
    "#     print(total,overall_product/total,dept_activities_product/total,kpi_product/total,department_product/total)\n",
    "#     item['department_product'] = department_product/total\n",
    "#     item['dept_activities_product'] = dept_activities_product/total\n",
    "#     item['kpi_product'] = kpi_product/total\n",
    "#     item['overall_product'] = overall_product/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7+0.7+0.8+0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('department_product', ascending=False)\n",
    "top = df.groupby('Value_3').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.models.levels import KPIWeightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIWeightings.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_object = KPIWeightings.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightings = []\n",
    "\n",
    "for weight in range(1,len(weight_object)):\n",
    "    weightings.append(weight_object[weight].final_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.models.kpis import KpiValueset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3591.24 / 1795.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = KpiValueset._meta.fields\n",
    "cols = []\n",
    "for column in column_names:\n",
    "#     print(column_names[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "# generate_ data\n",
    "datasets = KpiValueset.objects.update_or_create(status='N',main_id=37,maptype_id=3,maplist_id=3,individual_id=2,levelset_id=8,\n",
    "                                      value=50,value_dates=date(2020,2,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_date_exp = KpiValueset.objects.filter(value_dates__gte=date(2020,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_date_exp[0].value_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_date_exp[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_exp = KPIWeightings.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_percentage = kpi_exp[67].weight/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_date_exp[0].value * weight_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_date_contains = KpiValueset.objects.filter(value_dates__contains=date(2020,3,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_value = value_date_contains[0].value;second_value = value_date_contains[1].value\n",
    "first_value,second_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.models import Avg,Sum,Count\n",
    "KpiValueset.objects.filter(value_dates__contains=date(2020,3,31)).aggregate(avg=Avg('value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(67.0+53.0)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.models import Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputData.objects.filter(Q(number_of_levels=1)&Q(levelset_id=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(matching_string):\n",
    "    query_2 = KPIWeightings.objects.filter(content_id__name__icontains=matching_string).values(\"final_weight\")\n",
    "    df_2 = pd.DataFrame(query_2)\n",
    "    cleaned_weights = df_2.dropna()\n",
    "    return cleaned_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpis(matching_string):\n",
    "    data  = InputData.objects.filter(name=matching_string)\n",
    "    number_of_levels = []\n",
    "    level = []\n",
    "    for i in range(0,len(data)):\n",
    "        number_of_levels.append(data[i].number_of_levels)\n",
    "        level.append(data[i].levelset_id)\n",
    "    upscale = 1\n",
    "    tree_id = [x + upscale for x in number_of_levels] \n",
    "    kpi_query = InputData.objects.filter(Q(number_of_levels=tree_id[0])&Q(levelset_id=level[0]))\n",
    "    kpi_df = pd.DataFrame(kpi_query)\n",
    "    cleaned_df = kpi_df.dropna()\n",
    "    cleaned_df.columns = [\"kpis\"]\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kpis('Actval Life System')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputData.objects.filter(name='System Definition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = InputData.objects.filter(name__icontains='act')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_levels = []\n",
    "level = []\n",
    "for i in range(0,len(data)):\n",
    "    number_of_levels.append(data[i].number_of_levels)\n",
    "    level.append(data[i].levelset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_dates(matching_string):\n",
    "    required_data = df[df['name'].str.contains(matching_string)]\n",
    "    preprocessed_value_dates = required_data['value_date']\n",
    "    cleaned_value_dates = preprocessed_value_dates.reset_index()\n",
    "    cleaned_value_dates.columns = ['indices','value_dates']\n",
    "    return cleaned_value_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = str(InputData.objects.all().query)\n",
    "df = pd.read_sql_query(query, connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_dates(matching_string):\n",
    "    data  = InputData.objects.filter(name__iexact=matching_string)\n",
    "    value_dates = []\n",
    "    for i in range(0,len(data)):\n",
    "        value_dates.append(data[i].value_date)\n",
    "    return value_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_value_dates('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpis(matching_string):\n",
    "    data  = InputData.objects.filter(name=matching_string)\n",
    "    number_of_levels = []\n",
    "    level = []\n",
    "    for i in range(0,len(data)):\n",
    "        number_of_levels.append(data[i].number_of_levels)\n",
    "        level.append(data[i].levelset_id)\n",
    "    upscale = 1\n",
    "    tree_id = [x + upscale for x in number_of_levels]\n",
    "    if matching_string == None:\n",
    "        tree_id=[0]\n",
    "        level=[0]\n",
    "    else:\n",
    "        tree_id=tree_id\n",
    "        level = level\n",
    "    kpi_query = InputData.objects.filter(Q(number_of_levels=tree_id[0])&Q(levelset_id=level[0]))\n",
    "#     kpi_df = pd.DataFrame(kpi_query)\n",
    "#     cleaned_df = kpi_df.dropna()\n",
    "#     cleaned_df.columns = [\"kpis\"]\n",
    "    return kpi_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kpis('System Definition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIWeightings.objects.filter(content_id__name__exact='Good').values(\"final_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateset = 'February 13, 2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '.' in dateset:\n",
    "    value_date = datetime.strptime(dateset, '%b. %d, %Y')\n",
    "else: \n",
    "    value_date = datetime.strptime(dateset, '%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.models.kpis import KpiStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = KpiStats.objects.filter(pk__lte=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_get_keys = []\n",
    "for keys in range(0,len(data)):\n",
    "    list_get_keys.append(data[keys].pk)\n",
    "KpiStats.objects.filter(Q(pk__in=list_get_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sabb(stg, value, happiness):\n",
    "    sabbatical = (value + happiness + sum(1 for c in stg if c in \"sabbatical\")) > 22\n",
    "    return \"Sabbatical! Boom!\" if sabbatical else \"Back to your desk, boy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabb(\"Can I have a sabbatical?\",5,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = str(KPIWeightings.objects.all().query)\n",
    "df = pd.read_sql_query(query, connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "dataset = KPIWeightings.objects.filter(content_id__name__exact='Good')\n",
    "dates = [v.effective_date for v in dataset]\n",
    "value_dataset = InputData.objects.filter(name__exact='Good')\n",
    "match_dates = [v.value_date for v in value_dataset]\n",
    "\n",
    "nearest_val = []\n",
    "for date_ in dates:\n",
    "    match_date_list = [match for match in match_dates if date_ <= match]\n",
    "    if match_date_list:\n",
    "        nearest_val.append(date_)\n",
    "latest_date = sorted(nearest_val)[-1]\n",
    "    \n",
    "        \n",
    "KPIWeightings.objects.filter(effective_date=latest_date)\n",
    "# dates,match_dates,dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nearest_val)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = ['2019-01-01']\n",
    "latest_date[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4400+2000+1200+4700+2200+400+800+1300+1200+3000+1500+1500+400+2500+2000+700+4000+600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.models.levels import InputData\n",
    "from django.db.models import Count\n",
    "current_number_of_levels = InputData.objects.aggregate(level_count=Count('number_of_levels',distinct=True))\n",
    "counts_ = current_number_of_levels['level_count']\n",
    "counts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.filters import WeightFilter\n",
    "\n",
    "weighted_list_mapper = {}\n",
    "for i in range(counts_):\n",
    "    \n",
    "    weight_list = KPIWeightings.objects.filter(\n",
    "            ~Q(content_id__levelset_id=None) & Q(content_id__number_of_levels__exact=i)).order_by('-created_at')\n",
    "    weighted_list_mapper.update({i:weight_list})\n",
    "# weight_filter = WeightFilter(request.GET, queryset=weight_list)\n",
    "weighted_list_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InputData.objects.filter(n.first().number_of_levels\n",
    "InputData.objects.filter(pk=31).values(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 \n",
    "dataset_one= KPIWeightings.objects.filter(\n",
    "                        Q(content_id__levelset_id=None) & Q(content_id__number_of_levels__exact=index+1) & Q(\n",
    "                            created_at__gt=F('created_at') - timezone.timedelta(seconds=3))).values(\n",
    "                        \"content_id__name\").annotate(Count(\"content_id\"))\n",
    "# dataset_two= KPIWeightings.objects.filter(\n",
    "#                         Q(content_id__levelset_id=None) & Q(content_id__number_of_levels__exact=index) & Q(\n",
    "#                             created_at__gt=F('created_at') - timezone.timedelta(seconds=3))).values(\n",
    "#                         \"content_id__name\").annotate(Count(\"content_id\"))\n",
    "# dataset = dataset_two or dataset_one\n",
    "dataset_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "77/187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_set = []\n",
    "weight_set_two = []\n",
    "for indexes in range(0, len(dataset)):\n",
    "    weight_set.insert(indexes, KPIWeightings.objects.filter(\n",
    "        content_id__name=dataset[indexes]['content_id__name']).values('weight').annotate(\n",
    "        content=F('content_id__name'), contents=F('content_id')).order_by(\n",
    "        'created_at').last())\n",
    "    \n",
    "for indexes in range(0, len(dataset_two)):\n",
    "    weight_set_two.insert(indexes, KPIWeightings.objects.filter(\n",
    "        content_id__name=dataset_two[indexes]['content_id__name']).values('weight').annotate(\n",
    "        content=F('content_id__name'), contents=F('content_id')).order_by(\n",
    "        'created_at').last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_set_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " values = pd.DataFrame(weight_set)\n",
    "values\n",
    "weights = values.weight\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "a = [['a','b'], ['c']]\n",
    "list(itertools.chain.from_iterable(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures = []\n",
    "i = 0\n",
    "while i <= counts_:\n",
    "    data_structures.append(InputData.objects.filter(~Q(levelset_id=None) & Q(number_of_levels__exact=i)))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(itertools.chain.from_iterable(data_structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"setup.settings\")\n",
    "import django\n",
    "django.setup()\n",
    "\n",
    "from pams_system.models.levels import InputData,Level, KPIWeightings\n",
    "from django.db import connection\n",
    "import pandas as pd\n",
    "\n",
    "query = str(KPIWeightings.objects.all().query)\n",
    "df = pd.read_sql_query(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = df[(df.kpis == 'Good') & (df.content_id == 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dataset = filtered_dataset['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_dataset = filtered_dataset['weight'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange_based_on_time = filtered_dataset.sort_values(by='created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange_based_on_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset.groupby('weight').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dataset = df[(df.kpis == 'I tried') | (df.content_id == 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset.groupby('content_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_categories = len(df.groupby('content_id'))\n",
    "length_of_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df.groupby('content_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_element(x):\n",
    "    x.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].groupby([df['content_id'],df['kpis']]).apply(get_last_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].groupby([df['content_id'],df['kpis']]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIWeightings.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputData.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"setup.settings\")\n",
    "import django\n",
    "\n",
    "django.setup()\n",
    "\n",
    "from pams_system.models.levels import InputData, KPIWeightings\n",
    "from django.db.models import Q\n",
    "from datetime import date, datetime\n",
    "from django.db import connection\n",
    "import pandas as pd\n",
    "\n",
    "query = str(InputData.objects.all().query)\n",
    "df = pd.read_sql_query(query, connection)\n",
    "# data cleaning\n",
    "df[['value_date']] = df[['value_date']].astype(object).where(df[['value_date']].notnull(), None)\n",
    "\n",
    "\n",
    "def get_kpis(matching_string):\n",
    "    data = InputData.objects.filter(name=matching_string)\n",
    "    pk = []\n",
    "    number_of_levels = []\n",
    "    levelset = []\n",
    "    for i in range(0, len(data)):\n",
    "        pk.append(data[i].pk)\n",
    "        number_of_levels.append(data[i].number_of_levels)\n",
    "        levelset.append(data[i].levelset_id)\n",
    "    upscale = 1\n",
    "    tree_id = [x + upscale for x in number_of_levels]\n",
    "    if matching_string == None:\n",
    "        tree_id = [0]\n",
    "        levelset = [0]\n",
    "        pk = [0]\n",
    "    else:\n",
    "        tree_id = tree_id\n",
    "        levelset = levelset\n",
    "        pk = pk\n",
    "    kpi_query = InputData.objects.filter(Q(number_of_levels=tree_id[0]) & Q(parent_id=pk[0]) & Q(levelset_id=levelset[0]))\n",
    "    return kpi_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kpis('System Definition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.models.kpis import KpiAssignee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KpiAssignee.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(matching_string):\n",
    "    dataset = KPIWeightings.objects.filter(content_id__name__exact=matching_string)\n",
    "    dates = [v.effective_date for v in dataset]\n",
    "    value_dataset = InputData.objects.filter(name__exact=matching_string)\n",
    "    match_dates = [v.value_date for v in value_dataset]\n",
    "\n",
    "    nearest_val = []\n",
    "    for date_ in dates:\n",
    "        match_date_list = [match for match in match_dates if date_ <= match]\n",
    "        if match_date_list:\n",
    "            nearest_val.append(date_)\n",
    "    cleaned_weights = ''\n",
    "    if nearest_val:\n",
    "        latest_date = sorted(nearest_val)[-1]\n",
    "        query_2 = KPIWeightings.objects.filter(effective_date=latest_date).values(\"final_weight\").annotate(weight_kpi=F(\"content_id__name\"),created=F(\"created_at\"))\n",
    "        df_2 = pd.DataFrame(query_2)\n",
    "        cleaned_weights = df_2.dropna()\n",
    "        exact_weight = cleaned_weights[(cleaned_weights['weight_kpi'])==matching_string]\n",
    "        sorted_weights = exact_weight.sort_values(by=\"created\")\n",
    "        latest_weight = pd.DataFrame(sorted_weights.iloc[-1]).transpose()\n",
    "    return latest_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weights('Authentication Defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KpiStats.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(list1, val): \n",
    "    return(all(x <= val for x in list1)) \n",
    "\n",
    "def get_weights(matching_string):\n",
    "    dataset = KPIWeightings.objects.filter(content_id__name__exact=matching_string)\n",
    "    dates = [v.effective_date for v in dataset]\n",
    "    value_dataset = InputData.objects.filter(name__exact=matching_string)\n",
    "    match_dates = [v.value_date for v in value_dataset]\n",
    "\n",
    "    nearest_val = []\n",
    "    for date_ in dates:\n",
    "        match_date_list = [match for match in match_dates if [date_] <= match]\n",
    "        if match_date_list:\n",
    "            nearest_val.append(date_)\n",
    "    cleaned_weights = ''\n",
    "    if nearest_val:\n",
    "        latest_date = sorted(nearest_val)[-1]\n",
    "        query_2 = KPIWeightings.objects.filter(effective_date=latest_date).values(\"final_weight\").annotate(weight_kpi=F(\"content_id__name\"),created=F(\"created_at\"))\n",
    "        df_2 = pd.DataFrame(query_2)\n",
    "        cleaned_weights = df_2.dropna()\n",
    "        exact_weight = cleaned_weights[(cleaned_weights['weight_kpi'])==matching_string]\n",
    "        sorted_weights = exact_weight.sort_values(by=\"created\")\n",
    "        latest_weight = pd.DataFrame(sorted_weights.iloc[-1]).transpose()\n",
    "        return latest_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weights('Filled out Outline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pams_system.models.levels import InputData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputData.objects.all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
